---
title: "Introduction: Stata to R"
author: "Lucy Hackett"
date: "7/8/2020"
output: 
  html_document:
    theme: yeti
    highlight: haddock 
    # code_folding: show
    toc: yes
    toc_depth: 4
    toc_float: yes
    keep_md: true
---

<style type="text/css">
body, td {
   font-size: 14px;
}
code.r{
  font-size: 16px;
}
pre {
  font-size: 16px
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Wecome to the introductory R Markdown document! In this short tutorial, we will take a shallow dive into the use of R (with a focus on the tidyverse) for reading, inspecting, cleaning and manipulating data. There are MANY excellent intros to R and data wrangling out there. To name a few:

* [Modern Dive](https://moderndive.com/index.html)
* [Tiago Ventura's Intro](https://tiagoventura.rbind.io/files/gsa_tidyverse_workshop)
* [D-Lab's workshops](https://dlab.berkeley.edu/training)

As well as hundreds of tutorials on DataCamp. I will not attempt to recreate these resources. Rather, view this guide as a "translation" of stata-ish syntax and logic to the R system. Therefore I will not go into detail about the different objects and syntax that I use here, but rather will work through practical examples of how things would be done in Stata vs. R

Also note that the flexibility of R allows for many potential ways to do things, making it difficult and probably ill-advised for me to create a one-to-one dictionary of Stata commands to R commands. While this can be overwhelming and confusing at first, with time I think you'll find that flexibility is actually a great feature that allows you to choose the right/most efficient/easiest method depending on your particular data structure or needs.

## Importing packages

In R we have what's called "base R" and there are packages. Base R has tons of capabilities for statistical and probability work, but packages expand this capability by providing us with more specialized commands for things like data visualization, data cleaning and Econometric models. In Stata, use of external packages is less prevalent, but you still may use external packages such as ```ivreg2``` or ```binscatter```, which you gain access to by a one-time installation via ```ssc install```. In R, we can do this either through the package manager window on the lower right side of RStudio, or through the ```install.packages()``` command. Once we have installed the package, in order to use it we call the following: 

```{r lib, results="hide", message=FALSE}
library(dplyr)
library(ggplot2)
library(haven)
```

## Directories, importing data 

When working in Stata, frequently the first line in any dofile is ``cd``. In R, we set our current directory with:

```{r cd, eval=FALSE}
setwd('/users/hackettl/drive_berkeley/GSI_GSR/2020_fall/tutorials')
```

```{r cd1, eval=TRUE, echo=FALSE}
setwd('/users/hackettl/drive_berkeley/GSI_GSR/2020_fall/tutorials/pandas_for_stata_users/intro_stata_to_r_files')
```

A great advantage of R over Stata is you can import many different kinds of files with realtive ease, and hold several datasets in memory at a time. Let's import a few files I have on hand.

**sinac_sample.dta** is a 1% random sample of birth registries from 2008 in Mexico. **cat_local_inegi.csv** is a dictionary of Mexican localities; it gives their name, state, municipality and population.

Here I use the most simple import, but like in insheet, you can choose to start/stop at certain csv rows, change the column names to lowercase, etc; for these options and many more, see the documentation.

Note that to read the birth data I use ``read_dta`` which is a command provided by the **haven** package.

```{r import1}
sinac <- read_dta('../data/sinac_sample.dta')
local <- read.csv('../data/cat_local_inegi.csv')
```

## Inspecting data

A good first step is always to take a look at the data; see how many (non-missing) observations we have, how the data behaves, etc. Here I show some examples of how to do this. In this section we will be mimicking Stata commands such as

* br
* sum
* bys: sum
* hist
* tab
* duplicates drop
* sort

I'll put the Stata command in a comment above the python command where possible, so if you're looking for a specific command, you can search this notebook for that command (i.e., search the document for "tab" for example.


```{r opt, echo=FALSE}
options(width = 100)
```

```{r br}
# br
head(sinac, row = 10)
```

I don't always love the information I can see from ``head()``, so if you want a more detailed look you can click on the dataset name in the Environment window (upper right in RStudio) to see a larger format of the data, though this isn't always bery efficient. You can also use this window to see a complete list of all the variables!

To get a quick look at some summary statistics of the data, you can use ``dfapply()`` which is an iterative function with the option "favstats":

```{r sum}
# sum sexo_nac
summary(sinac$sexo_nac)
```

Note that in R, we have to associate variables we are interested in with the dataset they belong to, because we may and in fact do in this case have several datasets in memory. To do this, we use the syntax ``dataset_name$variable_name``. In the tidyverse and in other packages, we can use the pipe ``%>%`` to pass identifying information or transformations onto the next operation:

```{r tab}
# tab atendio
sinac %>% count(atendio)
```


```{r drop_dup}
# duplicates drop, save to different data
sinac_unique <- sinac %>% distinct()
```


```{r bys}
# to do operations by groups, like bys: sum 
# (you can add more variables to the list at will)
# note that we need to ignore missing values with na.rm = TRUE
sinac %>% group_by(ent_res_cve) %>% 
  summarise(avg_weight = mean(peso_nac_vivo, na.rm = TRUE),
            min_weight = min(peso_nac_vivo, na.rm = TRUE))

```

Be careful saving data as grouped, as this may affect future modifications you make to the data in unexpected ways!

```{r sort}
# view the data sorted: sort
sinac %>% arrange(edad_madre,apgar)
# again, here I haven't saved this, I'm just looking at it. 
# To save this, set it equal to a name

```

Looks like the youngest mothers in our data are 9 years old. Let's plot mother's age to get a sense of the distribution:

```{r hist}

hist(sinac$edad_madre)

```

Here's a nicer version using ``ggplot``:

```{r gghist, message=FALSE}

ggplot(data = sinac, aes(x = edad_madre)) +
  geom_histogram(color="darkblue", fill="lightblue") + 
  xlab("Mother's age") + 
  theme_bw()
  
```

##  A note about object assignment
A theme you may have noted above is that we can do things to the data without changing the underlying data or even saving what we're doing. This may remind you of what you might do in Stata with ``preserve ... restore``, which is the only way in Stata (besides tempfiles I guess) to explore manipulations of the data without altering the underlying data.

This is one of the main advantages that R has over Stata; we can hold multiple data, or multiples versions/ manipulations of the data in memory, leaving our original dataset intact! 

## Data cleaning 

Now we've looked around a bit at the data, we're going to clean it. These type of commands in Stata are:

* rename
* replace
* gen
* collapse
* merge

First let's get these column names in English...

```{r rename_all}
# rename
# note that here I AM reassigning the data to save changes
sinac <- sinac %>% rename(mother_age = edad_madre,
                           no_preg = numero_embarazos,
                           length = talla_nac_vivo,
                           weight = peso_nac_vivo,
                           no_appts = tot_consult,
                           day_born = dia_nac_hijo,
                           mo_born = mes_nac_hijo,
                           yr_born = year_nac_hijo, 
                           sex = sexo_nac, 
                           gest_age = semanas_gest, 
                           type_doc = atendio)

sinac %>% head()
```

```{r replace}
# Let's change the state code from 99 to missing
# replace
# ifelse has arguments condition, what to do if true, then what to do if false
sinac <- sinac %>% mutate(ent_res_cve = 
                            ifelse(
                              ent_res_cve == 99,
                              NaN,
                              ent_res_cve
))

summary(sinac$ent_res_cve)
# good! looks like the max code is now 32 (the number of states in Mexico)
```


```{r gen}
# gen
# Now let's make a categorical variable for mother's schooling 
sinac <- sinac %>% mutate(schooling_cat = 
                           ifelse(
                             schooling_mother < 4,
                             1,
                             ifelse(
                               schooling_mother >= 4 & schooling_mother <= 6,
                               2,
                               3)
                           ))

summary(sinac$schooling_cat)

```

Now let's look at the distribution of these categories, which if you're curious correspond to completed secondary, completed high school, and more than high school:

```{r plotschool}

# first label my variable by making it a factor var

sinac <- sinac %>% mutate(school = factor(schooling_cat,
                                          levels = c(1,2,3),
                                          labels = c("Secondary", "HS", "HS+")
                                          )
                          )

ggplot(sinac, aes(school)) + 
  geom_bar(color="darkblue", fill="lightblue") + 
  labs(x = 'Schooling', y = '# observations') +
  theme_bw()
  

```

### Aggregating data (collapse)

Let's get the mean by state; to do this, we want to collapse by the variable 'ent_res_cve'. If you want to group by more variables, just add them to the list for the "by" option. You can also write your own funtions for the "FUN" option, which makes this method about as flexible as you could want!

```{r colmean}

## stata: collapse (mean) **, by(mun_res_cve ent_res_cve)
sinac_means <- sinac %>% 
  select(mother_age, weight, length, schooling_mother) %>% 
  aggregate(by=list(sinac$ent_res_cve),
            FUN = mean,
            na.rm = TRUE) %>%
  rename(ent_res_cve = Group.1)


```

```{r showmean, echo=FALSE}
library(knitr)
sinac_means %>% head(10) %>% kable()
```

### Merging 

In Stata, if you're like me you love the table Stata prints for you after a merge reporting how many observations were merged, vs. right- and left-only. This simple report gives us lots of hints about things that may be going wrong, differences in reporting between datasets, and many other sneaky data details. 

In R this is not done exactly the same, but we can still check for these issues using more flexible merge options. Here I will focus on the ``dplyr`` way of merging because it is intuitive, especially for Stata fans, though base R also has a merge function. 

In dplyr there are three separate commands for merging:

* ``inner_join()`` merges the tables and keeps only those observations found in both tables, like running ``keep if _m == 3`` after a Stata merge. 

* ``left_join()`` merges the tables and keeps only observations matched or unmatched but found in the "master" data, like running ``keep if _m == 3 | _m == 1`` in Stata. 

* ``right_join()`` merges the tables and keeps only observations matched or unmatched but found in the "merging" data, like running ``keep if _m == 3 | _m == 2`` in Stata. 

Thre are more fun commands available like ``semi_join()`` and ``anti_join()`` which can be very useful for several tricks we use merging for, like using merging to identify observations we want to keep or discard, but I won't go into those here.

Another nice feature of these join functions is that instead of renaming in order to get matching columns, dplyr will let us tell it that differently named columns across datasets are really the same. Let's see an example. 

Say I want to add to this dataset the population of each municipality. My dictionary is at the locality level, but I need the municipal level. So I'm going to follow these steps:

1. Collapse dictionary to municipal level
2. Merge


```{r coldic, echo=TRUE}
# we want total population, so our function for aggregation will be sum:
local_mun <- local %>% 
  select(CVE_ENT, CVE_MUN, POB_TOTAL) %>% 
  aggregate(by=list(local$CVE_ENT, local$CVE_MUN),
            FUN = sum,
            na.rm = TRUE) %>%
  rename(ent_res_cve = Group.1,
         mun_res_cve = Group.2) %>%
  select(ent_res_cve, mun_res_cve, POB_TOTAL)

```

```{r showcol, echo=FALSE}
local_mun %>% head(10) %>% kable()
```

You may look at this and think, wow, this is so much more work than just typing ``collapse (sum) POB_TOTAL, by(CVE_ENT CVE_MUN)``. And yes, it is wordier, but we are gaining a lot more control over our data by being more specific! Here I am telling R exactly what variables I want to work with, I can create my own function for aggregating, I am renaming variables in the process, and I end up with a dataset that if formatted exactly how I want it. 

If I wanted to, I could even do this collapse and instead of saving it with the name "loc_mun", I could create it and use it in the merge all in one line to save myself memory and not create extra objects that are really only intermediate steps. But let's take things one step at a time for now. 

Now for the merge. Some notes: 

* I don't care about the population in municipalities that don't match to my birth data, so I'll choose ``left_join()``. 
* If I don't specify "by", R will automatically find the columns that are named the same. But to ensure things are happening correctly, I'll go ahead and specify this category. 
* Note that the first data that I mention (in this case, "sinac") is the "left" data. In Stata terminology, this would be the "master" data. 
* Also thinking about Stata terminaology, there is no need to specify ``m:1``, ``1:m``, etc. R will merge all matching observations. 
* Below I cast the SINAC values to doubles "along the way" to make sure the data types match between databases.
* There are more great options you can use to further customize your join, check out the documentation for dplyr to learn more!

```{r merge, echo=TRUE}
sinac_merge <- sinac %>% 
  mutate(ent_res_cve = as.double(ent_res_cve),
         mun_res_cve = as.double(mun_res_cve)) %>%
  left_join(local_mun,
            by = c('ent_res_cve','mun_res_cve'))

```
```{r showmerge, echo=FALSE}
sinac_merge %>%
  select(ent_res_cve, 
         mun_res_cve, 
         weight, 
         mother_age,
         schooling_cat,
         POB_TOTAL) %>% 
  head(10) %>% kable()
```

Let's summarize our new population variable to see how many observations successfully matched:
```{r matchcheck, echo=TRUE}
summary(sinac_merge$POB_TOTAL)
```
Looks like 248 mothers did not have a municipality assigned to them. Let's check out these values to see what's going on. Next we'll summarize the municipal ID's, filtering the data to look at only observations where the population variable is NA. 

```{r matchcheck2, echo=TRUE}
sinac_merge %>% 
  filter(is.na(POB_TOTAL)) %>%
  select(mun_res_cve) %>%
  summary()

```

Looks like for all the births that did not match to a population point, the municipal ID is 999; this probably represents a missing value, so I'll count our merge as a success!

## Exporting data

Finally, it may be useful sometimes to export data. When I was using Stata, I would generally have tons of dta files saved in different formats ready to merge or use with other data. In R, this becomes largely unnecessary because you can manipulate several raw files in the same code and combine them in different ways. So in general I would expect that you save fewer files, which helps maintain order in your workspace. But should you need to, here's how:

```{r export, echo=TRUE}
# Similar to outsheet, save, saveold

# write.csv(sinac_merge, '../data/merged_data.csv')
```

There are also packages you can use to export to Stata, SAS, xls, even SPSS. 



